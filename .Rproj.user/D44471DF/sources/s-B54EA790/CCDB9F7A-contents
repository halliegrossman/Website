---
title: 'Project 2: Modeling, Testing, and Predicting'
author: "Hallie Grossman"
date: '05/01/2020'
output:
  pdf_document:
    toc: yes
  html_document:
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
---

```{r setup, include=FALSE}
library(knitr)
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
  # this hook is used only when the linewidth option is not NULL
  if (!is.null(n <- options$linewidth)) {
    x = knitr:::split_lines(x)
    # any lines wider than n should be wrapped
    if (any(nchar(x) > n)) x = strwrap(x, width = n)
    x = paste(x, collapse = '\n')
  }
  hook_output(x, options)
})

knitr::opts_chunk$set(echo = TRUE, eval = TRUE,fig.align="center",warning=FALSE,message=FALSE,fig.width=8, fig.height=5, linewidth=60)
options(tibble.width = 100,width = 100)
library(tidyverse)
library(sandwich)
library(lmtest)
library(car)
library(mvtnorm)
library(ggExtra)
library(heplots)
library(plotROC)
library(glmnet)
```

INTRODUCTION-
```{r}
ICU<-read.csv("https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/ICU.csv") %>% select(-c(1))
ICU<-ICU %>% mutate(Gender=ifelse(Sex==1,"Female","Male")) %>% mutate(Outcome=ifelse(Survive==1,"Survived","Died")) %>% mutate(Admission=ifelse(Emergency==1,"Emergency","Elective")) %>% mutate(Infected=ifelse(Infection==1,"Yes","No")) %>% mutate(AgeGroup=case_when(Age<=49 ~"Young", Age<=69~"Middle", Age>=70~"Older"))
```
I have chosen a dataset containing various details about patients in the ICU (Intensive Care Unit). The dataset contains information on 200 different patients (200 observations), and the original dataset contained the following variables: "ID" (patient ID code), "Survive" (where 1=patient survived to discharge and 0=patient died), "Age"" (in years), "AgeGroup" (where 1= young (under 50), 2= middle (50-69), 3 = old (70+)), "Sex" (where 1=female and 0=male), "Infection" (where 1=infection suspected and 0=no infection), "SysBP" (Systolic blood pressure measuerd in mmHg), "Pulse" (heart rate measured in beats per minute), and "Emergency" (where 1=emergency admission and 0=elective admission). However, I do manipulate some of these variales throughout the project which you will see (for example, change some binary variables to categorical). In addition, I removed the "ID" variable from the original dataset, as it was not useful nor of interest to me.


1. MANOVA
```{r}
#install.packages("car")
library(car)
library(mvtnorm); library(ggExtra)
#density plot
ggplot(ICU, aes(x = SysBP, y = Pulse)) +
  geom_point(alpha = .5) + geom_density_2d() + coord_fixed() + facet_wrap(~Infected)
#install.packages("heplots")
library(heplots)
ICU1<-data.frame(ICU)
ICU1$SysBP<- as.numeric(ICU1$SysBP)
ICU1$Pulse<- as.numeric(ICU1$Pulse)
ICU1$Infection <- as.logical(ICU1$Infection)
ICU1$Emergency <- as.logical(ICU1$Emergency)
boxM(cbind(SysBP,Pulse)~Infection, data=ICU1)
#MANOVA
man1<-manova(cbind(SysBP,Pulse)~Infected, data=ICU)
summary(man1)
#UNIVARIATE ANOVAS
summary.aov(man1)
#posthoc tests
ICU %>% group_by(Infected) %>% summarise(mean(SysBP), mean(Pulse))
pairwise.t.test(ICU$SysBP,ICU$Infected, p.adj="none")
pairwise.t.test(ICU$Pulse,ICU$Infected, p.adj="none")
#the probability of at least one type I error = 0.2262191
1-.05 #= 0.95
1-((0.95)^5)
1-0.7737809
#adjusted alpha = 0.01
.05/5
```
I performed a MANOVA to test whether two of my numeric variables (systolic blood pressure and pulse) differed by levels of one of my categorical variables (patients with suspected infections and patients with no infection). My hypotheses are shown below, followed by my results.

Ho: For each response variable (BP and Pulse), the means of the groups are equal 
Ha: For at least 1 response variable (either BP or Pulse), at least 1 group mean (either infected or non-infected) differs.

Significant differences among the means of at least one of the response variables (BP, Pulse, or both) were found between the two groups (infected and non-infected); Pillai trace = 0.14107, psuedo F (2,197) = 16.177, p = 3.125e-07 so p<0.0001. Univariate ANOVAs for each dependent variable (both BP and Pulse) were conducted as follow-up tests to the MANOVA. The univariate ANOVAs for both BP and Pulse were also significant, F(3,22) = 26.669 & p<.0001, F(3,22) = 89.883 & p<.0001, F(3,22) = 49.12 & p<.0001, F(3,22) = 29.157 & p<.0001, F(3,22) = 9.5026 & p<.0001, respectively. Post hoc analysis was performed conducting pairwise comparisons to determine which groups differed in BP and Pulse. In order to do so, I performed a post-hoc test for both ANOVAS (2), meaning I performed 2 t-tests. Since I did 1 MANOVA, 2 ANOVAS, and 2 t-tests, I should use alpha = .05/5 =  0.01. With this boneferri corrected significance level, both BP (p=0.0011) and Pulse (p=7.6e-06) were still found to be significant (p<0.01 for both). 
The assumptions I tested were multivariate normality and homogeneity of (co)variances, and both were met. I concluded multivariate normality was met because both of my dependent variables (BP and Pulse) had at least 25 observations. In addition, the bivariate densities for each group (infected and non-infected) looked pretty normal according to my plot. I concluded homogeneity of (co)variances was met because I performed a Box's M-test and found the p value to 0.7371 (p>0.05). Moreover, I should reject the null hypothesis because both of my response variables differed across the 2 groups.

2. RANDOMIZATION TEST
```{r}
survived_data <- subset(ICU, Outcome=="Survived")
died_data <- subset(ICU, Outcome=="Died")
survived_age <- survived_data$Age
died_age <- died_data$Age
outcome_data <- ICU$Outcome
age_data <- ICU$Age
t.test(survived_age,died_age)
#rando data
rando<-data.frame(age=c(age_data),outcome=c(outcome_data))
#mean age for survived = 55.65
rando %>% filter(outcome=="Survived") %>% summarise(mean(age))
#mean age for dead = 65.125
rando %>% filter(outcome=="Died") %>% summarise(mean(age))
#mean age dif
mean_age_dif <- 65.125 - 55.65
set.seed(348)
rand_dist<-vector()
for(i in 1:5000){
new<-data.frame(age=sample(ICU$Age),outcome=ICU$Outcome)
rand_dist[i]<-mean(new[new$outcome=="Died",]$age)-
              mean(new[new$outcome=="Survived",]$age)}
#two tailed p value = 0.0062
mean(rand_dist>9.475 | rand_dist< -9.475)
{hist(rand_dist,main="",ylab=""); abline(v = c(9.475,-9.475),col="red")}
#indep t test for comparison = 0.003044
t.test(data=rando,age~outcome)
```
I conducted a randomization test to see whether there was a difference in average age (in years) between patients who died (n=40) and patients who survived (n=160) in the ICU. My null and alternative hypotheses are shown below. 

Ho : average age is the same for patients in the ICU who died vs. patients who survived
Ha : average age is different for patients in the ICU who died vs. patients who survived

First, I found the mean age for patients who died to be 65.125 years and the mean age for those who survived 55.65 years. Moreover, the mean differences value is 9.475 (65.125 - 55.65 = 9.475). I then performed a permutation test to find the proportion of my mean differences (simulated under the null hypothesis) that are more extreme than the actual value of +/- 9.475. I computed the two-tailed p-value to be 0.0062, which corresponds to the probability of observing a mean difference as extreme as the one I observed in my original data under this "randomized distribution." My p-value from the permutation test (p=0.0062) and the independent-samples t-test (p=0.003044) both indicate that I should reject the null hypothesis (p<0.05 for both). In conclusion, I should accept the null hypothesis stating that the true difference in mean ages is not equal to zero, so those who died and those who survived are not the same ages (on average).

3. LINEAR REGRESSION
```{r}
#dataset
ICU3<-ICU
#mean center numeric predictor variable (pulse)
ICU3$Pulse_c<-ICU3$Pulse-mean(ICU3$Pulse,na.rm = T)
ICU3$AgeGroup<-as.factor(ICU3$AgeGroup)
#model - relevel older age as reference group
ICU3$AgeGroup<-relevel(ICU3$AgeGroup,ref="Older")
fit3<-lm(SysBP ~ AgeGroup + Pulse_c + AgeGroup:Pulse_c, data= ICU3)
summary(fit3)
#regression plot
qplot(x = Pulse_c, y = SysBP, color = AgeGroup, data = ICU3) +
  stat_smooth(method = "lm", se = FALSE, fullrange = TRUE)
#ASSUMPTIONS
#linearity
resids<-fit3$residuals
fitvals<-fit3$fitted.values
ggplot()+geom_point(aes(fitvals,resids))+geom_hline(yintercept=0, color='red')
#normality - #Ho: pop is normally distributed 
shapiro.test(resids)
#HOMOSKEDACITY #HO: homoskedastic 
library(sandwich); library(lmtest)
bptest(fit3)
#regression with robust standard errors - corrected SE
coeftest(fit3, vcov = vcovHC(fit3))
summary(fit3)$r.sq
BP<-ICU3$SysBP
(sum((BP-mean(BP))^2)-sum(fit3$residuals^2))/sum((BP-mean(BP))^2)
sum((fitvals-mean(BP))^2)/sum((BP-mean(BP))^2)
```
I created a linear regression model to predict systolic blood pressure from age group, pulse (centered), and the interaction between age group and pulse rate. I made the older age group my reference model and obtained the following results...

Coefficient interpretation:
My model estimated the younger age group to have a coefficient of -3.8930, indicating that for patients with average pulse rates (controlling for pulse), younger patients are predicted to have a blood pressure that is 3.89296 lower than that of older aged patients, on average.
It predicted a coefficient of -0.7478 for the middle age group, indicating that for patients with average pulse rates (controlling for pulse), middle aged patients are predicted to have a blood pressure that is 0.7478 lower than that of older aged patients, on average.
It also predicted that for every 1 unit increase in pulse rate (bpm) among older patients, blood pressure goes down 0.2358 mmHg, on average.
In terms of interaction, my model predicted a coefficient of 0.2953 for the "AgeGroupYoung:Pulse_c" interaction, meaning the slope for Pulse on SysBP is 0.2953 greater for young patients comapared to older patients. Lastly, my model predicted a coefficient of 0.1172 for the "AgeGroupMiddle:Pulse_c"  interaction, meaning the slope for Pulse on SysBP is 0.3279 greater for middle aged patients comapared to older patients.

Assumption check:
Based on my plot showing residuals vs fitted values, I could confirm that the linearity assumption was met.
To assess normality, I performed a Shapiro-Wilk test which gave me an insignificant p-value of 0.07375. The null hypothesis for this test claims that the population is normally distributed, and since p > 0.05 we would fail to reject the null. Moreover, we can assume normality.
Based on the plot showing my residuals against my fitted values, I did not anticipate my data would meet the homoskedastic assumption. However, I performed a Breusch–Pagan test to make sure, and it confirmed that my data is heteroskedastic instead. It gave me a significant p-value (0.03123 < 0.05), so I rejected the null hypothesis, therefore concluding that homoskedacity is not met.

I then recomputed my regression with robust standard errors, and reanalyzed the significance of my coefficients. However, both models (the original and after recalculating with robust SEs) showed that none of them were significant. In both cases, all p values were greater than 0.05. There were minimal differences in terms of differences in the individual values (p-values, SEs, coefficients) as well.

To determine the proportion of the variation in the outcome that my model explains, I computed the R^2 value and found it to be 0.01915006. In other words, 0.01915006 of the variation in SysBP can be explained by my overall model (all predictors at once). The adjusted R squared value was also very close to zero (-0.00613).
    
4. BOOTSTRAPPED STANDARD ERRORS
```{r}
#bootstrap SEs 
#rows with replacement
boot_dat<- sample_frac(ICU3, replace=T)
samp_distn<-replicate(5000, {
boot_dat <- sample_frac(ICU3, replace=T) #bootstrap your data 
fit4<-lm(SysBP ~ AgeGroup + Pulse_c + AgeGroup:Pulse_c, data= boot_dat)
coef(fit4) #save coefs
 })
samp_distn %>% t %>% as.data.frame %>% summarize_all(sd)
#resids with replacement
fit4<-lm(SysBP ~ AgeGroup + Pulse_c + AgeGroup:Pulse_c, data= ICU3)#fit model
resids<-fit4$residuals  #save residuals
fitted<-fit4$fitted.values #save yhats
resid_resamp<-replicate(5000,{
    new_resids<-sample(resids,replace=TRUE) #resample resids w/ replacement
    ICU3$new_y<-fitted+new_resids #add new resids to yhats to get new "data"
    fit4<-lm(new_y ~ AgeGroup + Pulse_c + AgeGroup:Pulse_c, data= ICU3) #refit model
    coef(fit4) #save coefficient estimates (b0, b1, etc)
})
resid_resamp%>%t%>%as.data.frame%>%summarize_all(sd)
```

I then reran the regression model for a third time, but this time computing the bootstrapped standard errors. In addition to the robust SEs, the bootstrapped SEs also had very similar values to the original SEs. I did not observe any extreme changes between the SEs or p-values when comparing each of the different methods.

5. LOGISTIC REGRESSION
```{r}
library(tidyverse)
#install.packages("lmtest")
library(lmtest)
#install.packages("sandwich")
library(sandwich)
#model
fit5 <- glm(Survive ~ Age + SysBP, data = ICU, family = "binomial")
summary(fit5)
exp(coef(fit5))
#predicted probs
probs<-predict(fit5, type="response")
#confusion matrix
table(predict=as.numeric(probs>.5),truth=ICU$Survive)%>%addmargins
#sensitivity = 1
160/160
#specificity = 0.075
3/40
#precision = 0.8128
160/197
#accuracy = 0.815
(3+160)/200
#DENSITY plot
ICU$logit<-predict(fit5,type="link") #get log-odds for everyone
logit<-function(p)log(odds(p))
ICU %>% ggplot() + geom_density(aes(logit,color=Outcome,fill=Outcome), alpha=.4)+
  theme(legend.position=c(.85,.85))+geom_vline(xintercept=0)+xlab("logit (log-odds)")+
  geom_rug(aes(logit,color=Outcome)) 
#ROCPLOT
#install.packages("plotROC")
library(plotROC)
ROCplot<-ggplot(ICU)+geom_roc(aes(d=Survive,m=probs), n.cuts=0) 
ROCplot
#calculate AUC = 0.7016406
calc_auc(ROCplot)
#out of sample CV FOLD
class_diag<-function(probs,truth){
  
  tab<-table(factor(probs>.5,levels=c("FALSE","TRUE")),truth)
  acc=sum(diag(tab))/sum(tab)
  sens=tab[2,2]/colSums(tab)[2]
  spec=tab[1,1]/colSums(tab)[1]
  ppv=tab[2,2]/rowSums(tab)[2]
  
  if(is.numeric(truth)==FALSE & is.logical(truth)==FALSE) truth<-as.numeric(truth)-1
  
  #CALCULATE EXACT AUC
  ord<-order(probs, decreasing=TRUE)
  probs <- probs[ord]; truth <- truth[ord]
  
  TPR=cumsum(truth)/max(1,sum(truth)) 
  FPR=cumsum(!truth)/max(1,sum(!truth))
  
  dup<-c(prob[-1]>=prob[-length(prob)], FALSE)
  TPR<-c(0,TPR[!dup],1); FPR<-c(0,FPR[!dup],1)
  
  n <- length(TPR)
  auc<- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )
  
  data.frame(acc,sens,spec,ppv,auc)
}

#10 fold CV
set.seed(1234)
k=10

data1<-ICU[sample(nrow(ICU)),] #put dataset in random order
folds<-cut(seq(1:nrow(ICU)),breaks=k,labels=F) #create folds

diags<-NULL
for(i in 1:k){          # FOR EACH OF 10 FOLDS
  train<-data1[folds!=i,] # CREATE TRAINING SET
  test<-data1[folds==i,]  # CREATE TESTING SET
  
  truth<-test$Survive
  
  #fit<- glm(YOUR MODEL FROM ABOVE HERE, FIT TO TRAINING SET, i.e., data=train)
  fit5<- glm(Survive ~ Age + SysBP, data = train, family = "binomial")
  #probs<- predict(GET PREDICTED PROBABILITIES FROM TRAINED MODEL USING TESTING SET AS NEW DATA, i.e., newdata=test)
  prob<-predict(fit5,newdata = test,type="response")
  
  diags<-rbind(diags,class_diag(prob,truth)) #CV DIAGNOSTICS FOR EACH FOLD
}

summarize_all(diags,mean) #AVERAGE THE DIAGNOSTICS ACROSS THE 10 FOLDS
diags%>%summarize_all(mean)
```
I performed a logistic regression model to predict survival from age and systolic blood pressure. I obtained the following results...

Coefficient interpretation:
Controlling for age, SysBP has a significant positive impact on odds of survival (0.016831). For every additional 1mmHg increase in BP, odds of survival increase by factor of 1.016974. 
Controlling for BP, age has a significant negative impact on odds of survival (-0.028407). For every additional year in age (for every year older the patient is) odds of survival decrease by factor of 0.971993. 

According to my confusion matrix, the probability of predicting legendary and actually being legendary is 160/160, meaning the sensitivity/TPR is 1. Out of the 40 patients that did not survive, our model predicted only predicted that 3 of them would die, meaning the specitivity/TNR is 0.075. Out of the 197 patients that the model predicted to survive, 160 of them actually did survive, meaning the precision/PPV is 0.8128. The overall accuracy of the model is 0.815. I calculated the AUC to be 0.7016406, which is pretty fair (not great but not terrible)! After performing 10-fold cross validation, I computed the out-of-sample accuracy, sensitivity, and recall to be 0.81, 0.99375, and 0.07, respectively. 

6. LASSO REGRESSION
```{r}
#install.packages("glmnet")
library(glmnet)
ICU6 <- ICU %>% select(c(2,3,7,8,10,12,13))
y<-as.matrix(ICU6$Survive)
head(y)
x<-model.matrix(Survive~.,data=ICU6)[,-1] #grab predictors
head(x)
#standardize x
x<-scale(x)
cv<-cv.glmnet(x,y,family="binomial")
lasso<-glmnet(x,y,family="binomial",lambda=cv$lambda.1se)
coef(lasso)
#CV under LASSO model...
ICU6 <- ICU6 %>% mutate(Emergency=ifelse(Admission=="Emergency",1,0))
lassofit <- glm(Survive~Age+SysBP+Emergency, data=ICU6, family="binomial")
summary(lassofit)
probs<-predict(lassofit, type = "response")
#classification diagnostics
set.seed(1234)
k=10
data <- ICU6 %>% sample_frac #put rows of dataset in random order
folds <- ntile(1:nrow(data),n=10) #create fold labels
diags<-NULL
for(i in 1:k){
  train <- data[folds!=i,] #create training set (all but fold i)
  test <- data[folds==i,] #create test set (just fold i)
  truth <- test$Survive #save truth labels from fold i
  lassofit <- glm(Survive~Age+SysBP+Emergency, data=train, family="binomial")
  probs <- predict(lassofit, newdata=test, type="response")
  diags<-rbind(diags,class_diag(probs,truth))
}
diags%>%summarize_all(mean)
```
According to my lasso regression, the only variables that are retained are Age, SysBP, Admission, and Infected. I then created a model with only these variables and performed another 10-fold CV. Surprisingly, the out-of-sample accuracy from my lasso regression was lower than the accuracy of my original logistic regression. However, it was only a slight decrease (from 0.81 to 0.80) and the overall AUC increased about ~0.6 (from 0.7115717 to 0.7677385).
